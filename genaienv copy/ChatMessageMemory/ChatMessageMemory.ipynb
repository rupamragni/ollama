{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.smith.langchain.com\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "env_path = \"../OllamaSetup/.env\"  # Relative path from PromptTemplates\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Check if variables are loaded\n",
    "print(os.getenv(\"LANGCHAIN_ENDPOINT\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "base_url=\"http://localhost:11434\"\n",
    "#model = 'llama3.2:1b'\n",
    "# model='sheldon'\n",
    "model = 'llama3.2:3b'\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    base_url=base_url,\n",
    "    model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        ChatPromptTemplate,\n",
    "                                        PromptTemplate\n",
    ")\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Xyz from ABC! Is there something I can help you with or would you like to chat?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template= ChatPromptTemplate.from_template(\"{prompt}\")\n",
    "chain= template | llm | StrOutputParser()\n",
    "\n",
    "about= \"My name is xyz. I work for abc\"\n",
    "chain.invoke({'prompt':about})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't have any information about your name. I'm a large language model, I don't retain personal data or remember individual users. Each time you interact with me, it's a new conversation and I don't have any prior knowledge about you. Would you like to tell me your name?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt= \"What is my name?\"\n",
    "chain.invoke({'prompt':prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable with Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Community Edition installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import langchain_community\n",
    "print(\"LangChain Community Edition installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        ChatPromptTemplate,\n",
    "                                        PromptTemplate,\n",
    "                                        MessagesPlaceholder\n",
    ")\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///chat_history.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable_with_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/q_0xfydn1ysbg3dg6_yj25th0000gn/T/ipykernel_9181/4235610081.py:2: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 1.0. Use connection instead.\n",
      "  history=get_session_history(user_id)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='My name is xyz. I work for abc', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"It appears that you are trying to send a message using the HumanMessage object.\\n\\nHere's an example of how you can use it:\\n\\n```python\\nfrom humans import HumanMessage\\n\\n# Create a new HumanMessage object\\nmessage = HumanMessage(content='My name is xyz. I work for abc', additional_kwargs={}, response_metadata={})\\n\\nprint(message.content)  # Output: My name is xyz. I work for abc\\n```\\n\\nHowever, without more information about the environment or context in which this code is being used, it's difficult to provide a more specific answer.\\n\\nIf you could provide more details about what you're trying to accomplish with this code, I'd be happy to try and help further.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id= '121'\n",
    "history=get_session_history(user_id)\n",
    "history.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is xyz. I work for abc'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It appears you\\'re providing a human message in the format expected by the Hugging Face Transformers library.\\n\\nHere\\'s a breakdown of what this code snippet does:\\n\\n- `[HumanMessage`]: This indicates that the content that follows is a human-generated message.\\n- `(content=\\'My name is xyz. I work for abc\\')`: The `content` parameter contains the actual text message you want to be processed, in this case, \"My name is xyz. I work for abc\".\\n- `(additional_kwargs={})`: This parameter allows you to pass additional keyword arguments that might be required by the model or any downstream processing steps. In this case, it\\'s an empty dictionary (`{}`).\\n- `(response_metadata={})`: Similar to `additional_kwargs`, this parameter allows you to pass metadata about the response from a human model. It\\'s also an empty dictionary in this example.\\n\\nIn essence, this code snippet is setting up a message for a conversational AI or chatbot that can engage with humans.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke([HumanMessage(content=about)],\n",
    "                             config={'configurable': {'session_id' : user_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This appears to be an example of how to create and structure messages in the Hugging Face Transformers library, specifically for use in conversational AI or chatbot applications.\\n\\nThe code defines two `HumanMessage` instances:\\n\\n1. The first message is from a human user (`xyz`) and contains the text \"My name is xyz. I work for abc.\" This indicates that the content is a human-generated message.\\n2. The second message is also from a human user, but asks \"What is my name?\".\\n\\nBoth messages are created using the `HumanMessage` class, which takes in three parameters:\\n- `content`: The actual text of the message.\\n- `additional_kwargs`: Additional keyword arguments that might be required by the model or downstream processing steps. In this case, both instances use an empty dictionary (`{}`).\\n- `response_metadata`: Metadata about the response from a human model. Again, both instances use an empty dictionary (`{}).`\\n\\nThe structure of these messages is consistent with what\\'s expected by the Hugging Face Transformers library for conversational AI or chatbot applications.\\n\\nHere are some key takeaways:\\n\\n*   The `HumanMessage` class is used to create structured messages from humans.\\n*   These messages can be used as input to a conversational AI or chatbot.\\n*   The content, additional keyword arguments, and response metadata are all specified when creating the message instance.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke([HumanMessage(content=\"What is my name?\")],\n",
    "                             config={'configurable': {'session_id' : user_id}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message History with Dictionary Like inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = SystemMessagePromptTemplate.from_template(\"You are helpful assistant.\")\n",
    "human = HumanMessagePromptTemplate.from_template(\"{input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =[system, MessagesPlaceholder(variable_name='history'),human]\n",
    "prompt = ChatPromptTemplate(messages=messages)\n",
    "chain= prompt | llm | StrOutputParser()\n",
    "runnable_with_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key='input',history_messages_key='history')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm(session_id,input):\n",
    "    output = runnable_with_history.invoke(\n",
    "        {'input': input},\n",
    "        config={'configurable':{'session_id': session_id}}\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, XYZ from ABC! How can I assist you today? Do you have any questions or need help with something specific?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id='rr'\n",
    "chat_with_llm(user_id,about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your name is XYZ. However, I should note that you didn't give me your actual first and last names earlier. Is there a particular reason why you'd like to share them now?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_llm(user_id,\"What is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
